# GenAIGlossary
A glossary of terms in Generative AI and their details.

## Back story
It's becoming difficult to catch up with the AI space. This doc will can be used as a refresher to keep track of the terms and their details in the Generative AI space.

## Glossary
| Term | Description            | Source     |
| ---- | :--------------------- | :--------- |
|AGI        |	Artificial general intelligence, A concept that suggests a more advanced version of AI than we know today, one that can perform tasks much better than humans while also teaching and advancing its own capabilities.	
|BART       |	Bidirectional and Auto-Regressive Transformers	                                    |       https://arxiv.org/pdf/1910.13461.pdf
|BERT       |	Bidirectional Encoder Representations from Transformers	                            |       https://towardsdatascience.com/keeping-up-with-the-berts-5b7beb92766
|BLOOM      |	BigScience Large Open-science Open-access Multilingual Language Model	            |       https://bigscience.huggingface.co/
|ERNIE      |	Enhanced Representation through kNowledge IntEgration	                            |       https://arxiv.org/abs/1904.09223
|FAIR       |	Facebook AI Research	
|FLAN       |	Fine tuning Language models	                                                        |       https://arxiv.org/pdf/2210.11416.pdf
|HNSW       |	Hierarchical Navigable Small Worlds	                                                |       https://arxiv.org/ftp/arxiv/papers/1603/1603.09320.pdf
|LLaMA      |	Large Language Model Meta AI	                                                    |       https://ai.meta.com/blog/large-language-model-llama-meta-ai/
|LLM        |	Large Language Model: An AI model trained on mass amounts of text data to understand language and generate novel content in human-like language.	
|ML         |	Machine Learning, A component in AI that allows computers to learn and make better predictive outcomes without explicit programming. Can be coupled with training sets to generate new content.	
|MLM        |	Masked Language Model	
|NeurIPS    |	Neural Information Processing System	                                            |       https://neurips.cc/
|NLP        |	Natural language processing. A branch of AI that uses machine learning and deep learning to give computers the ability to understand human language, often using learning algorithms, statistical models and linguistic rules.	
|NSP        |	Next Sentence Prediction	
|PEFT       |	Parameter Efficient Fine-Tuning	                                                    |       https://huggingface.co/blog/peft
|RoBERTa    |	Robustly Optimized BERT Approach	                                                |       https://arxiv.org/pdf/1907.11692.pdf
|T5         |	Text to Text Transfer Transformer	                                                |       https://huggingface.co/docs/transformers/model_doc/t5
|XLM        |	Cross-lingual Language Models	                                                    |       https://arxiv.org/pdf/1901.07291.pdf
|XLU        |	Cross-lingual Understanding	
|XNLI       |	Cross-lingual Natural Language Inference	                                        |       https://github.com/facebookresearch/XNLI

---
Note: _PRs are accepted. Feel free to add more terms and their details._