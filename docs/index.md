## Glossary

### A
| Term                                                                         | Description                                                                                                                                                                                                                                                                                               |
| ---------------------------------------------------------------------------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| [A100](https://en.wikipedia.org/wiki/Ampere_%28microarchitecture%29)         | Ampere 100, A GPU variant named after French mathematician and physicist [André-Marie Ampère](https://en.wikipedia.org/wiki/Andr%C3%A9-Marie_Amp%C3%A8re)                                                                                                                                                 |
| AGI                                                                          | Artificial general intelligence, A concept that suggests a more advanced version of AI than we know today, one that can perform tasks much better than humans while also teaching and advancing its own capabilities.                                                                                     |
| [ALIGN](https://blog.research.google/2021/05/align-scaling-up-visual-and-vision.html) | **A** **L**arge-scale **I**ma**G**e and **N**oisy-Text Embedding, 1.8 Billion Image-Text pairs dataset by Google.                                                                                                                                                                                |                                     

### B
| Term                                                                         | Description                                                                                                                                                                                                                                                                                               |
| ---------------------------------------------------------------------------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| [BART](https://arxiv.org/pdf/1910.13461.pdf)                                 | **B**idirectional and **A**uto-**R**egressive **T**ransformers, an LLM by Google.                                                                                                                                                                                                                                                            |
| [BELEBELE](https://arxiv.org/pdf/2308.16884.pdf)                             | A Bambara word meaning "big, large, fat, great". This is a dataset containing 900 unique multiple-choice reading comprehension questions, each associated with one of 488 distinct passages                                                                                                               |
| [BERT](https://towardsdatascience.com/keeping-up-with-the-berts-5b7beb92766) | **B**idirectional **E**ncoder **R**epresentations from **T**ransformers, an LLM by Google.                                                                                                                                                                                                                                                   |
| [BIG-Bench](https://openreview.net/forum?id=uyTL5Bvosj)                      | **B**eyond the **I**mitation **G**ame **Bench**mark, a benchmark for measuring the performance of language models across a diverse set of tasks.                                                                                                                                                          |
| [BiT](https://arxiv.org/abs/1912.11370)                                      | **Bi**g **T**ransfer, a family of transfer learning models pre-trained on large datasets.                                                                                                                                                                                                                         |
| [BLEU](https://en.wikipedia.org/wiki/BLEU)                                   | **B**i**l**ingual **E**valuation **U**nderstudy, a metric for evaluating a generated sentence to a reference sentence.                                                                                                                                                                                                    |
| [BLOOM](https://bigscience.huggingface.co/)                                  | **B**igScience **L**arge **O**pen-science **O**pen-access **M**ultilingual Language Model                                                                                                                                                                                                                                     |
| [BPE](https://en.wikipedia.org/wiki/Byte_pair_encoding)                      | **B**yte **P**air **E**ncoding, a tokenization method.                                                                                                                                                                                                                                                                |

### C
| Term                                                                         | Description                                                                                                                                                                                                                                                                                               |
| ---------------------------------------------------------------------------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| [C4](https://www.tensorflow.org/datasets/catalog/c4)                         | The **C**olossal **C**lean **C**rawled **C**orpus, a dataset of 800GB of English text collected from the web.                                                                                                                                                                                                             |
| [Chinchilla](https://arxiv.org/abs/2203.15556)                               | Chinchilla is a 70B parameters model trained as a compute-optimal model with 1.4 trillion tokens by Deepmind.                                                                                                                                                                                             |
| [CLIP](https://openai.com/blog/clip/)                                        | **C**ontrastive **L**anguage-**I**mage **P**re-training, maps data of different modalities, text and images, into a shared embedding space.                                                                                                                                                                               |
| [CoQA](https://stanfordnlp.github.io/coqa/)                                  | CoQA is a large-scale dataset for building **Co**nversational **Q**uestion **A**nswering systems. CoQA contains 127,000+ questions with answers collected from 8000+ conversations.                                                                                                                       |

### D
| Term                                                                         | Description                                                                                                                                                                                                                                                                                               |
| ---------------------------------------------------------------------------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| [DALL-E](https://openai.com/research/dall-e)                                 | It is a portmanteau of the names of animated robot Pixar character _WALL-E_ and the Spanish surrealist artist _Salvador Dalí_.                                                                                                                                                                            |
| [DPR](https://arxiv.org/pdf/2004.04906.pdf)                                  | **D**ense **P**assage **R**etrieval                                                                                                                                                                                                                                                                                   |

### E
| Term                                                                         | Description                                                                                                                                                                                                                                                                                               |
| ---------------------------------------------------------------------------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| [ELMo](https://arxiv.org/pdf/1802.05365v2.pdf)                               | **E**mbeddings from **L**anguage **Mo**dels                                                                                                                                                                                                                                                                           |
| [ERNIE](https://arxiv.org/abs/1904.09223)                                    | **E**nhanced **R**epresentation through k**N**owledge **I**nt**E**gration                                                                                                                                                                                                                                 |
| [ELECTRA](https://arxiv.org/pdf/2003.10555.pdf)                              | **E**fficiently **L**earning an **E**ncoder that **C**lassifies **T**oken **R**eplacements **A**ccurately                                                                                                                                                                                                                             |

### F
| Term                                                                         | Description                                                                                                                                                                                                                                                                                               |
| ---------------------------------------------------------------------------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| FAIR                                                                         | **F**acebook **AI** **R**esearch                                                                                                                                                                                                                                                                                      |
| [FLAN](https://arxiv.org/pdf/2210.11416.pdf)                                 | **F**ine tuning **Lan**guage models                                                                                                                                                                                                                                                                               |
| [FLOPS](https://en.wikipedia.org/wiki/FLOPS)                                 | **Fl**oating Point **O**perations **P**er **S**econd                                                                                                                                                                                                                                                                      |
| [FLoRes](https://github.com/facebookresearch/flores)                         | **F**acebook **Lo**w **Res** Machine Translation Benchmark is a low-resource MT dataset.                                                                                                                                                                                                                  |

### G
| Term                                                                         | Description                                                                                                                                                                                                                                                                                               |
| ---------------------------------------------------------------------------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| [GGML](https://huggingface.co/TheBloke/Llama-2-13B-chat-GGML)                | **G**eorgi **G**erganov **M**achine **L**earning, a C library focused on machine learning                                                                                                                                                                                                                                 |
| [GLaM](https://arxiv.org/abs/2112.06905v2)                                   | **G**eneralist **La**nguage **M**odel, a family of language models which uses a sparsely activated mixture-of-experts architecture to scale the model capacity while also incurring substantially less training cost compared to dense variants.                                                                      |
| [GSM8K](https://arxiv.org/pdf/2109.01152.pdf)                                | **G**rade **S**chool **M**ath **8K**, GSM8K is a dataset of 8.5K high quality linguistically diverse grade school math word problems created by human problem writers.                                                                                                                                                    |
| GOFAI                                                                        | **G**ood **O**ld-**F**ashioned **A**rtificial **I**ntelligence                                                                                                                                                                                                                                                                |

### H
| Term                                                                         | Description                                                                                                                                                                                                                                                                                               |
| ---------------------------------------------------------------------------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| [HNSW](https://arxiv.org/ftp/arxiv/papers/1603/1603.09320.pdf)               | **H**ierarchical **N**avigable **S**mall **W**orlds                                                                                                                                                                                                                                                                       |

### I
| Term                                                                         | Description                                                                                                                                                                                                                                                                                               |
| ---------------------------------------------------------------------------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| [ILSVRC2012](https://www.image-net.org/challenges/LSVRC/2012/)               | **I**mageNet **L**arge **S**cale **V**isual **R**ecognition **C**hallenge 2012, a competition to estimate the content of photographs for the purpose of retrieval and automatic annotation using a subset of the large hand-labeled ImageNet dataset (10,000,000 labeled images depicting 10,000+ object categories) as training. |

### J
| Term                                                                         | Description                                                                                                                                                                                                                                                                                               |
| ---------------------------------------------------------------------------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| [JFT](https://arxiv.org/abs/1503.02531.pdf)                                  | JFT-300M is an internal Google dataset used for training image classification models. Images are labeled using an algorithm that uses complex mixture of raw web signals, connections between web-pages and user feedback.                                                                                |

### L
| Term                                                                         | Description                                                                                                                                                                                                                                                                                               |
| ---------------------------------------------------------------------------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| [LAION-400M](https://arxiv.org/abs/2111.02114.pdf)                           | **L**arge-scale **A**rtificial **I**ntelligence **O**pen **N**etwork, an open dataset of CLIP-Filtered 400 Million Image-Text Pairs                                                                                                                                                                                           |
| [LaMDA](https://arxiv.org/pdf/2201.08239.pdf)                                | **La**nguage **M**odel for **D**ialogue **A**pplications                                                                                                                                                                                                                                                                  |
| [LLaMA](https://ai.meta.com/blog/large-language-model-llama-meta-ai/)        | **L**arge **La**nguage **M**odel Meta **A**I                                                                                                                                                                                                                                                                              |
| [LLaSM](https://arxiv.org/pdf/2308.15930.pdf)                                | **L**arge **La**nguage and **S**peech **M**odel                                                                                                                                                                                                                                                                           |
| LLM                                                                          | **L**arge **L**anguage **M**odel: An AI model trained on mass amounts of text data to understand language and generate novel content in human-like language.                                                                                                                                                          |
| [LLaVA](https://arxiv.org/abs/2304.08485)                                    | **L**arge **La**nguage and **V**ision **A**ssistant, an end-to-end trained large multimodal model that connects a vision encoder and LLM for general purpose visual and language understanding.                                                                                                                           |
| [LMM](https://arxiv.org/abs/2204.14198)                                      | **L**arge **M**ultimodal **M**odels, models for visual instructions like DeepMind’s Flamingo, Google’s PaLM-E, Salesforce’s BLIP, Microsoft’s KOSMOS-1, Tencent’s Macaw-LLM; Chatbots like ChatGPT and Gemini are LMMs.                                                                                               |

### M
| Term                                                                         | Description                                                                                                                                                                                                                                                                                               |
| ---------------------------------------------------------------------------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| [M3W](https://arxiv.org/pdf/2204.14198.pdf)                                  | Multi Modal Massive Web, an image and text dataset by DeepMind. This is used to train Flamingo, a multimodal LLM.                                                                                                                                                                                         |
| [MAWPS](https://github.com/sroy9/mawps)                                      | A Math Word Problem Repository is an online repository of Math Word Problems, to provide a unified testbed to evaluate different algorithms.                                                                                                                                                              |
| ML                                                                           | Machine Learning, A component in AI that allows computers to learn and make better predictive outcomes without explicit programming. Can be coupled with training sets to generate new content.                                                                                                           |
| MLP                                                                          | Multi Level Perceptron, a deep artificial neural network. It is a collection of more than one perceptron.                                                                                                                                                                                                 |
| MLM                                                                          | Masked Language Model                                                                                                                                                                                                                                                                                     |
| [MMLU](https://arxiv.org/abs/2009.03300)                                     | Massive Multitask Language Understanding, a new test to measure a text model's multitask accuracy                                                                                                                                                                                                         |
| MRC                                                                          | Machine Reading Comprehension                                                                                                                                                                                                                                                                             |
| [MTPB](https://arxiv.org/pdf/2203.13474.pdf)                                 | Multi-Turn Programming Benchmark, a benchmark consisting of 115 diverse problem sets that are factorized into multi-turn prompts                                                                                                                                                                          |

### N
| Term                                                                         | Description                                                                                                                                                                                                                                                                                               |
| ---------------------------------------------------------------------------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| [NeurIPS](https://neurips.cc/)                                               | Neural Information Processing System                                                                                                                                                                                                                                                                      |
| NLP                                                                          | Natural language processing. A branch of AI that uses machine learning and deep learning to give computers the ability to understand human language, often using learning algorithms, statistical models and linguistic rules.                                                                            |
| NLG                                                                          | Natural Language Generation. A branch of AI that uses machine learning and deep learning to generate human-like language.                                                                                                                                                                                 |
| NLU                                                                          | Natural Language Understanding, to understand the relationship and meaning in text data.                                                                                                                                                                                                                  |
| NSP                                                                          | Next Sentence Prediction                                                                                                                                                                                                                                                                                  |

### P
| Term                                                                         | Description                                                                                                                                                                                                                                                                                               |
| ---------------------------------------------------------------------------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| [PALM](https://arxiv.org/pdf/2204.02311.pdf)                                 | Pathways Language Model                                                                                                                                                                                                                                                                                   |
| [PEFT](https://huggingface.co/blog/peft)                                     | Parameter Efficient Fine-Tuning                                                                                                                                                                                                                                                                           |
| [PPO](https://arxiv.org/pdf/1707.06347.pdf)                                  | Proximal Policy Optimization, foundational RL algorithm for learning from human preferences                                                                                                                                                                                                               |
| [POMDP](https://en.wikipedia.org/wiki/Partially_observable_Markov_decision_process) | Partially Observable Markov Decision Process, a model for decision making in situations where outcomes are partly random and partly under the control of a decision maker.                                                                                                                         |
### R
| Term                                                                         | Description                                                                                                                                                                                                                                                                                               |
| ---------------------------------------------------------------------------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| [RAG](https://arxiv.org/pdf/2005.11401.pdf)                                  | Retriever-Augmented Generation is an AI framework that combines an information retrieval component with a text generation model to improve the quality of responses generated by LLMs.                                                                                                                    |
| [ResNet](https://arxiv.org/abs/1512.03385)                                   | A Residual Neural Network (a.k.a. Residual Network, ResNet) is a deep learning model in which the weight layers learn residual functions with reference to the layer inputs.                                                                                                                              |
| [RLHF](https://arxiv.org/pdf/2305.18438.pdf)                                 | Reinforcement Learning from Human Feedback                                                                                                                                                                                                                                                                |
| [RoBERTa](https://arxiv.org/pdf/1907.11692.pdf)                              | Robustly Optimized BERT Approach                                                                                                                                                                                                                                                                          |
| [ROGUE](https://arxiv.org/abs/1803.01937)                                    | Recall-Oriented Understudy for Gisting Evaluation, a metric for evaluating a generated sentence to a reference sentence.                                                                                                                                                                                  |
| [RoPE](https://arxiv.org/abs/2104.09864)                                     | **Ro**tary **P**osition **E**mbedding, an upgrade to traditional sinusodial positional embedding on Transformer architecture. Check [this video](https://www.youtube.com/watch?v=o29P0Kpobz0) for more details.                                                                                           |

### S
| Term                                                                         | Description                                                                                                                                                                                                                                                                                               |
| ---------------------------------------------------------------------------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| SFT                                                                          | Supervised Fine Tuning, A fine-tuning method especially in LLMs                                                                                                                                                                                                                                           |
| [SQuAD](https://arxiv.org/pdf/1606.05250.pdf)                                | Stanford Question Answering Dataset                                                                                                                                                                                                                                                                       |
| [SVAMP](https://github.com/arkilpatel/SVAMP)                                 | Simple Variations on Arithmetic Math word Problems is a challenge set to enable more robust evaluation of automatic MWP (Math Word Problem) solvers                                                                                                                                                       |
| SLM                                                                          | It can be both Small Language Model or Statistical Language Model                                                                                                                                                                                                                                         |

### T
| Term                                                                         | Description                                                                                                                                                                                                                                                                                               |
| ---------------------------------------------------------------------------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| [T5](https://huggingface.co/docs/transformers/model_doc/t5)                  | Text to Text Transfer Transformer                                                                                                                                                                                                                                                                         |

### V
| Term                                                                         | Description                                                                                                                                                                                                                                                                                               |
| ---------------------------------------------------------------------------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| [ViT](https://arxiv.org/abs/2010.11929)                                      | Vision Transformer, a vision model based as closely as possible on the Transformer architecture originally designed for text-based tasks.                                                                                                                                                                 |
| VLU                                                                          | Vision Language Understanding, like Natural Language Understanding (NLU) but for images                                                                                                                                                                                                                   |
| [VRAM](https://en.wikipedia.org/wiki/Video_random-access_memory)             | Video Random Access Memory, a special type of memory that stores graphics data for the GPU.                                                                                                                                                                                                               |

### X
| Term                                                                         | Description                                                                                                                                                                                                                                                                                               |
| ---------------------------------------------------------------------------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| [XLM](https://arxiv.org/pdf/1901.07291.pdf)                                  | Cross-lingual Language Models                                                                                                                                                                                                                                                                             |
| XLU                                                                          | Cross-lingual Understanding                                                                                                                                                                                                                                                                               |
| [XNLI](https://github.com/facebookresearch/XNLI)                             | Cross-lingual Natural Language Inference                                                                                                                                                                                                                                                                  |
| [XLNet](https://arxiv.org/pdf/1906.08237.pdf)                                | Generalized Autoregressive Pretraining for Language Understanding                                                                                                                                                                                                                                         |

### Z
| Term                                                                         | Description                                                                                                                                                                                                                                                                                               |
| ---------------------------------------------------------------------------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| [ZeRO](https://arxiv.org/pdf/1910.02054.pdf)                                 | **Ze**ro **R**edundancy **O**ptimizer                                                                                                                                                                                                                                                                     |

---
Note: _PRs are accepted. Feel free to add more terms and their details._